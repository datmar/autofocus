{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Process raw data.\"\"\"\n",
    "from functools import partial\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "autofocus_path = os.path.abspath(os.path.join('../../..'))\n",
    "if autofocus_path not in sys.path:\n",
    "    sys.path.append(autofocus_path)\n",
    "from autofocus.build_dataset.lpz_2016_2017.ops import (\n",
    "    record_is_grayscale,\n",
    "    record_mean_brightness,\n",
    "    trim_bottom,\n",
    ")\n",
    "from autofocus.build_dataset.helpers import has_channels_equal\n",
    "\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from typing import DefaultDict\n",
    "\n",
    "from creevey import CustomReportingPipeline\n",
    "from creevey.load_funcs.image import load_image_from_disk\n",
    "from creevey.ops.image import resize\n",
    "from creevey.path_funcs import replace_dir\n",
    "from creevey.util.image import find_image_files\n",
    "from creevey.write_funcs.image import write_image\n",
    "from fastai.vision import verify_images\n",
    "import pandas as pd\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath\n",
    "current = abspath('')\n",
    "\n",
    "DATASET_NAME = current\n",
    "REPO_DIR = dirname(dirname(dirname(current)))\n",
    "DATA_DIR = f\"{REPO_DIR}/data/\"\n",
    "PathOrStr = Union[Path, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DIM = 512\n",
    "N_JOBS = 5\n",
    "NUM_PIXELS_TO_TRIM = 1\n",
    "\n",
    "THIS_DATASET_DIR = DATA_DIR + \"lpz_2012-2014/lpz_2012-2014/\"\n",
    "RAW_IMG_DIR = THIS_DATASET_DIR + 'raw/'\n",
    "# RAW_CSV_FILENAMES = [\"detections_2016.csv\", \"detections_2017.csv\"]\n",
    "# RAW_CSV_PATHS = [RAW_DIR / fn for fn in RAW_CSV_FILENAMES]\n",
    "\n",
    "PROCESSED_DIR = THIS_DATASET_DIR + \"processed/\"\n",
    "PROCESSED_IMAGE_DIR = PROCESSED_DIR + \"images/\"\n",
    "# PROCESSED_LABELS_CSV_OUTPATH = PROCESSED_DIR / \"labels.csv\"\n",
    "\n",
    "# CORRUPTED_FILES = [\n",
    "#     RAW_DIR / \"images_2016\" / \"DPT\" / \"D03-AMP1\" / \"._CHIL - D03-AMP1-JU16_00037.JPG\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THIS IS FROM HELPERS>PY\n",
    "\n",
    "# def has_channels_equal(image: np.array) -> bool:\n",
    "#     \"\"\"\n",
    "#     Indicate whether all channels have equal values.\n",
    "\n",
    "#     Assumes that channels lie along the final axis.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     image\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     True if all channels have equal values, including when there is only\n",
    "#     one channel as long as there is an axis corresponding to that\n",
    "#     channel (e.g. a grayscale image with shape height x width x 1, but\n",
    "#     not one with shape height x width).\n",
    "\n",
    "#     \"\"\"\n",
    "#     first_channel = image[..., 0]\n",
    "#     return all(\n",
    "#         [\n",
    "#             np.equal(image[..., channel_num], first_channel).all()\n",
    "#             for channel_num in range(1, image.shape[-1])\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THIS IS FROM OPS.PY\n",
    "# def trim_bottom(image: np.array, num_pixels: int, **kwargs) -> np.array:\n",
    "#     \"\"\"\n",
    "#     Trim off the bottom of an image.\n",
    "\n",
    "#     `kwargs` included only for compatibility with Creevey's\n",
    "#     `CustomReportingPipeline`\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     image\n",
    "#     num_pixels\n",
    "#         Height of strip to trim off the bottom of the image, in pixels\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     Trimmed image\n",
    "\n",
    "#     \"\"\"\n",
    "#     return image[:-num_pixels, :]\n",
    "\n",
    "\n",
    "# def record_mean_brightness(\n",
    "#     image: np.array, inpath: PathOrStr, log_dict: DefaultDict[str, dict]\n",
    "# ) -> np.array:\n",
    "#     \"\"\"\n",
    "#     Record the mean brightness of image.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     image\n",
    "#     inpath\n",
    "#         Image input path\n",
    "#     log_dict\n",
    "#         Dictionary of image metadata\n",
    "\n",
    "#     Side effect\n",
    "#     -----------\n",
    "#     Adds a \"mean_brightness\" item to log_dict[inpath]\n",
    "\n",
    "#     \"\"\"\n",
    "#     is_grayscale = has_channels_equal(image)\n",
    "\n",
    "#     if is_grayscale:\n",
    "#         image_gray = image\n",
    "#     else:\n",
    "#         image_gray = cv.cvtColor(src=image, code=cv.COLOR_RGB2GRAY)\n",
    "\n",
    "#     log_dict[inpath][\"mean_brightness\"] = image_gray.mean()\n",
    "\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def record_is_grayscale(\n",
    "#     image: np.array, inpath: PathOrStr, log_dict: DefaultDict[str, dict]\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Record whether image is grayscale.\n",
    "\n",
    "#     In this dataset, grayscale images have been saved as three-channel\n",
    "#     images with all three channels equal, so this function checks for\n",
    "#     equality across channels rather than the number of channels.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     image\n",
    "#     inpath\n",
    "#         Image input path\n",
    "#     log_dict\n",
    "#         Dictionary of image metadata\n",
    "\n",
    "#     Side effect\n",
    "#     -----------\n",
    "#     Adds a \"grayscale\" item to log_dict[inpath]\n",
    "\n",
    "#     \"\"\"\n",
    "#     is_grayscale = has_channels_equal(image)\n",
    "\n",
    "#     log_dict[inpath][\"grayscale\"] = int(is_grayscale)\n",
    "\n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_DIR = RAW_IMG_DIR + 'SP12/DPT/D02-HUP1-SP12/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_images():\n",
    "    # Bottom 198 pixels are often a footer of camera information. I\n",
    "    # suspect that those pixels are more likely to lead the model to\n",
    "    # learn batch effects that do not generalize than to lead to genuine\n",
    "    # learning, so I remove them.\n",
    "    trim_footer = partial(trim_bottom, num_pixels=NUM_PIXELS_TO_TRIM)\n",
    "    resize_min_dim = partial(resize, min_dim=MIN_DIM)\n",
    "    ops = [trim_footer, resize_min_dim, record_is_grayscale, record_mean_brightness]\n",
    "\n",
    "    trim_resize_pipeline = CustomReportingPipeline(\n",
    "        load_func=load_image_from_disk, ops=ops, write_func=write_image\n",
    "    )\n",
    "\n",
    "    image_paths = find_image_files(TEST_IMG_DIR)\n",
    "    path_func = partial(replace_dir, outdir=PROCESSED_IMAGE_DIR)\n",
    "\n",
    "    run_record = trim_resize_pipeline.run(\n",
    "        inpaths=image_paths,\n",
    "        path_func=path_func,\n",
    "        n_jobs=N_JOBS,\n",
    "        skip_existing=False,\n",
    "        exceptions_to_catch=ZeroDivisionError,\n",
    "    )\n",
    "    logging.info(\"Checking for additional corrupted images\")\n",
    "    run_record = _delete_bad_images(run_record)\n",
    "    \n",
    "    return run_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _delete_bad_images(run_record):\n",
    "    verify_images(PROCESSED_IMAGE_DIR, delete=True)\n",
    "    is_file = run_record.loc[:, \"outpath\"].apply(os.path.isfile)\n",
    "    run_record = run_record.loc[is_file, :]\n",
    "\n",
    "    return run_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_seasons(file_name):\n",
    "    # For parsing the seasons from the File Names\n",
    "    # The season names are based on the codes provided by Lincoln Park Zoo researchers\n",
    "    file_name = file_name.split(\"-\")[3]\n",
    "    if file_name.startswith((\"JA\", \"WI\")):\n",
    "        return \"Winter\"\n",
    "    elif file_name.startswith((\"AP\", \"SP\")):\n",
    "        return \"Spring\"\n",
    "    elif file_name.startswith((\"JU\", \"SU\")):\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Fall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = DATA_DIR + 'lpz_2012-2014/lpz_2012-2014/raw/labels_clean.csv'\n",
    "RAW_CSV = pd.read_csv(LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_labels(run_record):\n",
    "    raw_df = (\n",
    "        pd.read_csv(RAW_CSV)\n",
    "        .set_index(\"FileName\")\n",
    "        .drop([\"Unnamed: 0\", Sure], axis=\"columns\")\n",
    "        .rename(columns={\"ShortName\": \"label\", \"ImageDate\": \"date\"})\n",
    "    )\n",
    "\n",
    "    run_record.index = pd.Series(run_record.index).apply(lambda path: Path(path).name)\n",
    "\n",
    "    processed_df = (\n",
    "        run_record.drop(\n",
    "            [\"skipped_existing\", \"exception_handled\", \"time_finished\"], axis=\"columns\"\n",
    "        )\n",
    "        .join(raw_df, how=\"left\")\n",
    "        .loc[:, [\"outpath\", \"label\", \"grayscale\", \"mean_brightness\", \"date\"]]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    processed_df.loc[:, \"filename\"] = processed_df.loc[:, \"outpath\"].apply(\n",
    "        lambda path: Path(path).name\n",
    "    )\n",
    "    processed_df.loc[:, \"location\"] = processed_df.loc[:, \"filename\"].apply(\n",
    "        lambda fn: fn.split(\"-\")[2]\n",
    "    )\n",
    "    processed_df.loc[:, \"season\"] = processed_df.loc[:, \"filename\"].apply(\n",
    "        _extract_seasons\n",
    "    )\n",
    "    processed_df = processed_df.drop(\"outpath\", axis=\"columns\")\n",
    "\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Process raw data.\n",
    "\n",
    "    Delete blacklisted corrupted images. Trim a footer from each image\n",
    "    and resize it to 512 pixels on its shorter dimension. Write results\n",
    "    to \"autofocus/data/processed/images\". Reformat labels from CSV and\n",
    "    write to a new file \"autofocus/data/processed/labels.csv\".\n",
    "\n",
    "    \"\"\"\n",
    "#     logging.info(\"Deleting known corrupted files\")\n",
    "#     for path in CORRUPTED_FILES:\n",
    "#         path.unlink()\n",
    "    logging.info(f\"Processing images and writing results to {PROCESSED_IMAGE_DIR}\")\n",
    "    run_record = _process_images()\n",
    "    \n",
    "#     logging.info(\"Processing labels\")\n",
    "#     labels = _process_labels(run_record)\n",
    "#     logging.info(f\"Writing processed labels to {PROCESSED_LABELS_CSV_OUTPATH }\")\n",
    "#     labels.to_csv(PROCESSED_DIR / \"labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    logging.basicConfig(format=\"%(levelname)s %(asctime)s %(message)s\")\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    main()\n",
    "\n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Completed in {round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_record = _process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_record.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai] *",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
